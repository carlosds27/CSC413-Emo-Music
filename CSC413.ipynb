{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca94547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN THE WHOLE CODE WITH THE DATASET AVAILABLE, GO TO THE GITHUB PAGE https://github.com/carlosds27/CSC413-Emo-Music\n",
    "# TO GENERATE MUSIC, RUN ALL OF THE CODE BELOW EXCEPT THE TRAINING BLOCK (THERE ARE SOME EXAMPLES ON HOW TO GENERATE MUSIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead555c9-e2b3-4661-925e-05328bcc67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from music21 import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a334c4-efef-4c68-a3db-9dea5c165518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = 'cuda_malloc_async'\n",
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfdf2926-ca82-4d29-8564-7ce540a5f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_path = \"EMOPIA_2.2/midis\"\n",
    "q1_midi = []\n",
    "q2_midi = []\n",
    "q3_midi = []\n",
    "q4_midi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e87be2-e5a6-4d2b-8a57-049c82e7793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "for q in [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
    "    notes = []\n",
    "    for f in glob.glob(os.path.join(midi_path, q + \"*\")):\n",
    "        # Translate the midi file into a stream of midi objects (notes and chords)\n",
    "        midi_file = converter.parse(f)\n",
    "        notes_to_parse = None\n",
    "        # Check if there are instruments\n",
    "        parts = instrument.partitionByInstrument(midi_file)\n",
    "        if parts: \n",
    "            # file has instrument parts\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else: \n",
    "            # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for n in notes_to_parse:\n",
    "            if isinstance(n, note.Note):\n",
    "                # if note then just append to notes\n",
    "                notes.append(str(n.pitch))\n",
    "            elif isinstance(n, chord.Chord):\n",
    "                # if chord use . to indicate it's a chord\n",
    "                notes.append('.'.join(str(k) for k in n.normalOrder))\n",
    "    if q == \"Q1\":\n",
    "        q1_midi = notes\n",
    "    elif q == \"Q2\":\n",
    "        q2_midi = notes\n",
    "    elif q == \"Q3\":\n",
    "        q3_midi = notes\n",
    "    elif q == \"Q4\":\n",
    "        q4_midi = notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e9db14-46b2-494b-9cbf-4cbb460da54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685\n"
     ]
    }
   ],
   "source": [
    "overall_notes = q1_midi + q2_midi + q3_midi + q4_midi\n",
    "# 500 notes is roughly 2.5 minutes?\n",
    "pitch_names = sorted(set(k for k in overall_notes))\n",
    "# Note to integer mapping\n",
    "note_vocab = dict((note, number) for number, note in enumerate(pitch_names))\n",
    "n_vocab = len(pitch_names)\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16177d42-d291-4676-b360-97591b7c3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(seq_len):\n",
    "    x_train = []\n",
    "    t_train = []\n",
    "    for q in [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
    "        x = []\n",
    "        t = []\n",
    "        notes = []\n",
    "        if q == \"Q1\":\n",
    "            notes = q1_midi\n",
    "        elif q == \"Q2\":\n",
    "            notes = q2_midi \n",
    "        elif q == \"Q3\":\n",
    "            notes = q3_midi\n",
    "        elif q == \"Q4\":\n",
    "            notes = q4_midi\n",
    "        for i in range(0, len(notes) - seq_len):\n",
    "            input_seq = notes[i:i+seq_len]\n",
    "            output = notes[i+seq_len]\n",
    "            x.append([note_vocab[k] for k in input_seq])\n",
    "            t.append(note_vocab[output])\n",
    "        # reshape x so that it fits well with LSTM\n",
    "        x = np.reshape(x, (len(x), seq_len, 1))\n",
    "        x = x / float(n_vocab)\n",
    "        t = to_categorical(t, num_classes=n_vocab)\n",
    "        x_train.append(x)\n",
    "        t_train.append(t)\n",
    "    return x_train, t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745ec1a2-db2c-48d6-a762-3824a37c1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing print out shape and values\n",
    "# print(len(x_train))\n",
    "# print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9043d524-3afa-4289-bd27-9120fafdb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(seq_len):\n",
    "    model = Sequential([\n",
    "        LSTM(512, input_shape=(seq_len, 1), return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(512, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(512),\n",
    "        Dense(256),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_vocab),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40edfa22-25ce-4819-9a8f-0266e38c4350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 22:05:03.868148: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.868284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.868350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.913144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.913248: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.913300: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-12-03 22:05:03.927140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 22:05:03.927234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10252 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-12-03 22:05:04.184316: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 512)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 512)          2099200   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100, 512)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 685)               176045    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 685)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5558445 (21.20 MB)\n",
      "Trainable params: 5558445 (21.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tm1 = create_LSTM_model(100)\n",
    "print(tm1.summary())\n",
    "# tm1.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "# tm1.fit(x_train[0][:10], t_train[0][:10], epochs=10, batch_size=2, verbose=1)\n",
    "# embedding_layer = tm1.layers[0]\n",
    "# embeddings = embedding_layer.get_weights()[0]\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e7bb1-29ac-4c6f-a729-0fd238012cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAINING BLOCK\n",
    "seq_lens = [200, 100, 50]\n",
    "batch_sizes = [128, 64]\n",
    "for s in seq_lens:\n",
    "    for bs in batch_sizes:\n",
    "        \n",
    "        print(\"Initializing Training process...\")\n",
    "        x_train, t_train = create_train_data(s)\n",
    "        \n",
    "        for i in range(len(x_train)):\n",
    "            \n",
    "            print(\"Creating our model...\")\n",
    "            model = create_LSTM_model(s)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "            print(\"Finished compiling our model\")\n",
    "\n",
    "            # Create a checkpoint path\n",
    "            checkpoint_path = f\"Model/lstm{i+1}-{s}s-{bs}bs.h5\"\n",
    "            model_path = Path(checkpoint_path)\n",
    "            model_exist = model_path.is_file()\n",
    "            checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "\n",
    "            if model_exist:\n",
    "                # If checkpoint exist, continue training with pretrained weights\n",
    "                print(\"Continue Training with pre-trained weights\")\n",
    "                model.load_weights(checkpoint_path)\n",
    "\n",
    "            print(f\"Start Training with {s=} {bs=} for Q{i+1}\")\n",
    "            history = model.fit(x_train[i], t_train[i], epochs=200, batch_size=bs, callbacks=[checkpoint])\n",
    "\n",
    "            print(\"Finished Training\")\n",
    "            \n",
    "            plot_name = f'Graph/lstm{i+1}-{s}s-{bs}bs.png'\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.title('Model Loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train'], loc='upper left')\n",
    "            plt.savefig(plot_name)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39132856-c868-4a95-8715-64db4f1ba0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference as inf_mod\n",
    "xt, yt = inf_mod.predict(\"midi_like\", \"ar_va\", \"dataset/sample_data/example_generative.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fba3c643-8a20-49af-92f0-21a6f9830494",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "batch_size = 128\n",
    "x, t = create_train_data(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(q, seq_len, batch_size):\n",
    "    model = create_LSTM_model(seq_len)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    model.load_weights(f'Model/lstm{q}-{seq_len}s-{batch_size}bs.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09171808-0782-419f-9cce-33ab68e8c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(q, model, music_len):\n",
    "    start = np.random.randint(0, len(x[q-1]))\n",
    "    # print(start)\n",
    "    pattern = x[q-1][start]\n",
    "    pattern = pattern * float(n_vocab)\n",
    "    # print(pattern * float(n_vocab))\n",
    "    output = []\n",
    "    # generate 500 notes\n",
    "    for _ in range(music_len):\n",
    "        input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        input = input / float(n_vocab)\n",
    "        # print(input[0])\n",
    "        prediction = model.predict(input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        \n",
    "        result = pitch_names[index]\n",
    "        output.append(result)\n",
    "        print(index)\n",
    "        pattern = np.append(pattern, [index])\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad40dca4-19c2-4689-98cd-062a91ea38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music(pred, filename, qs=[0,0,0,0]):\n",
    "    if sum(qs) == 0:\n",
    "        qs[q-1] = 1\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for p in pred:\n",
    "        # if a chord\n",
    "        if ('.' in p) or p.isdigit():\n",
    "            notes_in_chord = p.split('.')\n",
    "            notes = []\n",
    "            for n in notes_in_chord:\n",
    "                new_note = note.Note(int(n))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(p)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration\n",
    "        offsets = [0.4, 0.3, 0.5, 0.5]\n",
    "        probabilities = qs\n",
    "        t = random.choices(range(len(offsets)), weights=probabilities)[0]\n",
    "        inc = offsets[t]\n",
    "        offset += inc\n",
    "    music_stream = stream.Stream(output_notes)\n",
    "    music_stream.write('midi', fp=f'Gen-Music/{filename}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combination_prediction(qs, seq_len, batch_size, n):\n",
    "    if sum(qs) != 1.0 or len(qs) != 4:\n",
    "        print(\"qs total should be == 1 and len(qs) == 4\")\n",
    "        return []\n",
    "    model1 = load_model(1, seq_len, batch_size)\n",
    "    model2 = load_model(2, seq_len, batch_size)\n",
    "    model3 = load_model(3, seq_len, batch_size)\n",
    "    model4 = load_model(4, seq_len, batch_size)\n",
    "    q = qs.index(max(qs)) # use the maximum as start\n",
    "    start = np.random.randint(0, len(x[q]))\n",
    "    # print(start)\n",
    "    pattern = x[q][start]\n",
    "    pattern = pattern * float(n_vocab)\n",
    "    # print(pattern * float(n_vocab))\n",
    "    output = []\n",
    "    # generate 500 notes\n",
    "    for _ in range(n):\n",
    "        input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        input = input / float(n_vocab)\n",
    "        # print(input[0])\n",
    "        p1 = model1.predict(input, verbose=0)\n",
    "        p2 = model2.predict(input, verbose=0)\n",
    "        p3 = model3.predict(input, verbose=0)\n",
    "        p4 = model4.predict(input, verbose=0)\n",
    "        prediction = (qs[0]*p1) + (qs[1]*p2) + (qs[2]*p3) + (qs[3]*p4)\n",
    "        index = np.argmax(prediction)\n",
    "        \n",
    "        result = pitch_names[index]\n",
    "        output.append(result)\n",
    "        print(index)\n",
    "        pattern = np.append(pattern, [index])\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate music from each model\n",
    "seq_len = 100\n",
    "batch_size = 128\n",
    "for q in range(1, 5):\n",
    "    model = load_model(q, seq_len, batch_size)\n",
    "    pred = generate_prediction(q, model, 200)\n",
    "    generate_music(pred, f\"q{q}-{seq_len}s-{batch_size}bs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [0.2, 0.5, 0.2, 0.1] # Change this to preferable emotion\n",
    "pred = generate_combination_prediction(qs, seq_len, batch_size, 200)\n",
    "generate_music(pred, f\"q{q}-{seq_len}s-{batch_size}bs\", qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c33b81-25e6-4fdd-b372-cb42cfe6d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, xy = inf_mod.predict(\"midi_like\", \"ar_va\", f\"Music/q5-{seq_len}s-{batch_size}bs.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_music_from_emotion(emotion, n):\n",
    "    # Generate music from emotion provided or user input with desired length\n",
    "    qs = []\n",
    "    emotion = emotion.lower()\n",
    "    if emotion not in [\"happy\", \"calm\", \"sad\", \"angry\"]:\n",
    "        print(\"There are only Happy, Calm, Sad, Angry currently\")\n",
    "        t = input(\"Input your own quadrant value (e.g q1[happy] q2[angry] q3[sad] q4[calm]) (sum should be 1):\")\n",
    "        qs = [float(x) for x in t.split()]\n",
    "    if emotion == \"happy\":\n",
    "        qs = [1.0, 0, 0, 0]\n",
    "    elif emotion == \"calm\":\n",
    "        qs = [0, 0, 0, 1.0]\n",
    "    elif emotion == \"sad\":\n",
    "        qs = [0, 0, 1.0, 0]\n",
    "    elif emotion == \"angry\":\n",
    "        qs = [0, 1.0, 0, 0]\n",
    "    pred = generate_combination_prediction(qs, 100, 128, n)\n",
    "    if pred == []:\n",
    "        return\n",
    "    generate_music(pred, f\"{emotion}-generated-song\", qs)\n",
    "    print(f\"File saved in Gen-Music/{emotion}-generated-song.mid\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a angry song with a length of 200 notes\n",
    "create_music_from_emotion(\"angry\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If emotion doesn't exist input your own array of emotions \n",
    "create_music_from_emotion(\"scared\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the code above to generate this prediction !!!\n",
    "# IMPORTANT !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to train on volume\n",
    "# import pretty_midi\n",
    "# def extract_features_from_midi(file_path):\n",
    "#     midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    \n",
    "#     # Extracting volume information\n",
    "#     volumes = [note.velocity for instrument in midi_data.instruments for note in instrument.notes]\n",
    "    \n",
    "#     return volumes\n",
    "\n",
    "# def volume_features_dataset():\n",
    "#     vol_list = []\n",
    "#     for q in [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
    "#         vol = []\n",
    "#         for f in glob.glob(os.path.join(midi_path, q + \"*\")):\n",
    "#             v = extract_features_from_midi(f)\n",
    "#             vol.append(v)\n",
    "#         vol_list.append(vol)\n",
    "#     return vol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_arrs = volume_features_dataset()\n",
    "# for i in range(4):\n",
    "#     volume_arr = np.concatenate(volume_arrs[i])\n",
    "#     volume_arr = volume_arr / 127.0\n",
    "#     x_vol_train = np.reshape(volume_arr, (len(volume_arr)//seq_len, seq_len, 1))\n",
    "#     t_vol_train = volume_arr[seq_len:]\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(64, input_shape=(seq_len, 1)))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     # Create a checkpoint path\n",
    "#     cp = f\"Model/vol-lstm{i+1}-{seq_len}s-{batch_size}bs.h5\"\n",
    "#     model_path = Path(checkpoint_path)\n",
    "#     model_exist = model_path.is_file()\n",
    "#     checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "#     model.fit(x_vol_train, t_vol_train, epochs=10, batch_size=batch_size, callbacks=[checkpoint])\n",
    "# Tried (no time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
